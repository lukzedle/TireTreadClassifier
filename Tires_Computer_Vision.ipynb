{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["PH5vmRnMi3Er","RV2U5rlwjI6w"],"toc_visible":true,"authorship_tag":"ABX9TyNllnLdL4ccpiG1bKhxGdQ/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Introduction\n","\n","Tire selection plays a key role in ensuring road safety, especially in extreme weather conditions. The type of tires used on your vehicle depends on the season and weather conditions. Summer tires offer excellent traction in hot, dry conditions, while winter tires offer better traction in cold, ice, and snow. All-season tires are designed to perform well in both summer and winter. \n"," \n","The aim of this project is to develop a model for identifying the tire type, which distinguishes between summer, winter and all-season tires in particular. The data set used to train and test the model will contain images of tires with different tire wear patterns. \n"," \n"," The development of an accurate tire type recognition model could make a significant contribution to road safety by providing drivers with an automated means of ensuring they are using the correct tires for  current weather conditions. This project aims to harness the power of deep learning to create an efficient and effective tire type recognition system."],"metadata":{"id":"Kqu1aP4UvFNS"}},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"RWZovatuyIl4"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN-Zh2AS-EXk","executionInfo":{"status":"ok","timestamp":1683179089197,"user_tz":-120,"elapsed":111632,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"5353f44c-c710-42f0-c90a-326974d6fc42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Opony_Computer_Vision\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/Opony_Computer_Vision"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","import  random\n","import os\n","from io import BytesIO\n","from PIL import Image\n","import cv2\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential \n","from tensorflow.keras import layers"],"metadata":{"id":"Zgs4jVdw-lx7","executionInfo":{"status":"ok","timestamp":1683179095752,"user_tz":-120,"elapsed":922,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Scraping test"],"metadata":{"id":"it9LrCW5yLPm"}},{"cell_type":"code","source":["summer = '1'\n","winter = '2'\n","both = '3'\n","page = '1'\n","\n","\n","url = f'https://www.24opony.pl/szukaj.html?f=1&idproducent=0&idsezon={summer}&idrozmiar=0&idpojazd=1&czyxl=0&czyrf=0&inpre=0&cod=0&cdo=0&strona={page}&idmodel=0'\n","\n","content = requests.get(url).content\n","soup = BeautifulSoup(content, 'html.parser')"],"metadata":{"id":"owd3jU4B-oYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = ['https://www.24opony.pl' + image.find('img')['src'] for image in soup.find_all('a', {'rel':'prettyPhoto'})]"],"metadata":{"id":"Y5L9ldzW_LWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images[0].split('/')[-1].split('.')[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"AqYB8_oOCD9x","executionInfo":{"status":"ok","timestamp":1682622925698,"user_tz":-120,"elapsed":6,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"e45c1e35-4736-4543-f185-e144196b71db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'n_4164_s'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["images"],"metadata":{"id":"dL4GKwWEKRy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content = requests.get(images[0]).content"],"metadata":{"id":"Nos4qe9N_dE4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img  = Image.open(BytesIO(content))"],"metadata":{"id":"OMeEI9HTApw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img.max()"],"metadata":{"id":"Ub4DTkeQMMWn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Scraping"],"metadata":{"id":"hbz_MOzpyUfH"}},{"cell_type":"code","source":["def get_page(season, page_number):\n","  url = f'https://www.24opony.pl/szukaj.html?f=1&idproducent=0&idsezon={season}&idrozmiar=0&idpojazd=1&czyxl=0&czyrf=0&inpre=0&cod=0&cdo=0&strona={page_number}&idmodel=0'\n","  try:\n","    response = requests.get(url)\n","    content = response.content\n","    soup = BeautifulSoup(content, 'html.parser')\n","    time.sleep(0.5)\n","    return content\n","  except Exception as e:\n","    print(f'Error: {e}')\n","\n","def get_urls(content):\n","  soup = BeautifulSoup(content, 'html.parser')\n","  return set(['https://www.24opony.pl' + image.find('img')['src'] for image in soup.find_all('a', {'rel':'prettyPhoto'}) if not image.find('img')['src'].split('/')[-1].split('.')[0].startswith('brak_zdjecia')])\n","\n","\n","def sharpen_image(func):\n","  def wrapper(url):\n","    img = func(url)\n","    new_img = cv2.filter2D(img, -1, kernel=np.array([[0, -1, 0],\n","                                                [-1, 5, -1],\n","                                                [0, -1, 0]]))\n","    return new_img\n","  return wrapper\n","    \n","@sharpen_image\n","def get_image(url):\n","  try:\n","    content = requests.get(url).content\n","    img = Image.open(BytesIO(content))\n","    img = np.array(img)\n","    return img\n","  except Exception as e:\n","    print(f'Error: {e}')\n","\n","def save_image(img, url,season, path):\n","  file_name = url.split('/')[-1].split('.')[0] + '.jpg'\n","  os.makedirs(f'{path}/{season}', exist_ok=True)\n","  cv2.imwrite(f'{path}/{season}/{file_name}', img)\n","\n","def get_data(season, start_page, end_page, path):\n","  for page_number in range(start_page, end_page):\n","    content = get_page(season, page_number + 1)\n","    urls = get_urls(content)\n","\n","    for i, url in enumerate(urls):\n","      img = get_image(url)      \n","      save_image(img, url, season, path)\n","      time.sleep(1.0/100)\n","      if  i % 5 == 0:\n","        print(f'Download {i} images from page {page_number}/{end_page}')\n","\n"],"metadata":{"id":"_g0OsxUlBl8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dodaj lsitę z linkami, tak że gdy się link powtarza to skipuje\n","\n","get_data(1, 1, 400, 'data/train')\n","get_data(2, 1, 400, 'data/train')\n","get_data(3, 1, 400, 'data/train')"],"metadata":{"id":"MIlpxzGVD_9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_page(season, page_number):\n","  url = f'https://www.24opony.pl/szukaj.html?f=1&idproducent=0&idsezon={season}&idrozmiar=0&idpojazd=1&czyxl=0&czyrf=0&inpre=0&cod=0&cdo=0&strona={page_number}&idmodel=0'\n","  try:\n","    response = requests.get(url)\n","    content = response.content\n","    soup = BeautifulSoup(content, 'html.parser')\n","    time.sleep(0.5)\n","    return content\n","  except Exception as e:\n","    print(f'Error: {e}')\n","\n","def get_urls(content):\n","  soup = BeautifulSoup(content, 'html.parser')\n","  return set(['https://www.24opony.pl' + image['href'] for image in soup.find_all('a', {'rel':'prettyPhoto'}) if not image['href'].split('/')[-1].split('.')[0].startswith('brak_zdjecia')])\n","\n","\n","def sharpen_image(func):\n","  def wrapper(url):\n","    img = func(url)\n","    new_img = cv2.filter2D(img, -1, kernel=np.array([[0, -1, 0],\n","                                                [-1, 5, -1],\n","                                                [0, -1, 0]]))\n","    return new_img\n","  return wrapper\n","    \n","@sharpen_image\n","def get_image(url):\n","  try:\n","    content = requests.get(url).content\n","    img = Image.open(BytesIO(content))\n","    img = np.array(img)\n","    return img\n","  except Exception as e:\n","    print(f'Error: {e}')\n","\n","def save_image(img, url,season, path):\n","  file_name = url.split('/')[-1].split('.')[0] + '.jpg'\n","  os.makedirs(f'{path}/{season}', exist_ok=True)\n","  cv2.imwrite(f'{path}/{season}/{file_name}', img)\n","\n","def get_data(season, start_page, end_page, path):\n","  for page_number in range(start_page, end_page):\n","    content = get_page(season, page_number + 1)\n","    urls = get_urls(content)\n","\n","    for i, url in enumerate(urls):\n","      img = get_image(url)      \n","      save_image(img, url, season, path)\n","      time.sleep(1.0/100)\n","      if  i % 5 == 0:\n","        print(f'Download {i} images from page {page_number}/{end_page}')\n"],"metadata":{"id":"Qhg9GzENWE4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get_data(1, 1, 400, 'data/train_various_sizes')\n","# get_data(2, 1, 400, 'data/train_various_sizes')\n","get_data(3, 1, 400, 'data/train_various_sizes')"],"metadata":{"id":"GNg1bVeuWPFL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model"],"metadata":{"id":"cAvoNEnMtHo0"}},{"cell_type":"code","source":[],"metadata":{"id":"90EdJx4AtJO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lVuO2jF7Sy3","executionInfo":{"status":"ok","timestamp":1682837421158,"user_tz":-120,"elapsed":277,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"1c885665-91ef-4210-9313-dd2f760ed9ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["603\n","150\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3XdBAjLG1a6s","executionInfo":{"status":"ok","timestamp":1683179094834,"user_tz":-120,"elapsed":4841,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## First model\n","\n","The model is based on thumbnail photos in which the tread is barely visible. The images have been sharpened."],"metadata":{"id":"Zdrj7gR4VB6m"}},{"cell_type":"code","source":["test_size = 0.2\n","path = 'data'\n","\n","# for sub_type in ['1', '2', '3']:\n","#   os.makedirs(path + '/test' +f'/{sub_type}', exist_ok=True)\n","#   file_list = os.listdir(path + '/train/' + sub_type)\n","#   number_of_samples = int(len(file_list) * test_size)\n","\n","#   for file_name in random.sample(file_list, number_of_samples):\n","#     os.rename(path +'/train/' + sub_type + '/' + file_name,\n","#               path +'/test/' + sub_type + '/' + file_name)\n","\n","# train_path = 'data/train'\n","# test_path = 'data/test'\n","# print(len(os.listdir(train_path + '/1')))\n","# print(len(os.listdir(test_path + '/1')))"],"metadata":{"id":"WGDC5G3JpSaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = 'data/train'\n","\n","batch_size = 128\n","img_heights = 128\n","img_width = 128\n","\n"],"metadata":{"id":"Kv0Py6_t3KX6","executionInfo":{"status":"ok","timestamp":1683181858787,"user_tz":-120,"elapsed":308,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["train_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='training',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                    interpolation='bilinear',\n","                                                    seed=42)\n","\n","val_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='validation',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                  interpolation='bilinear',\n","                                                  seed=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLJwmhv23bpJ","executionInfo":{"status":"ok","timestamp":1683181861314,"user_tz":-120,"elapsed":1452,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"14f394bb-fff4-4fb1-d1e3-42ab6ea1ae0a"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1146 files belonging to 3 classes.\n","Using 917 files for training.\n","Found 1146 files belonging to 3 classes.\n","Using 229 files for validation.\n"]}]},{"cell_type":"code","source":["for img, label in train_ds:\n","  print(img.shape)\n","  print(label.shape)"],"metadata":{"id":"Eoy-sIxi7ygn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683179166635,"user_tz":-120,"elapsed":49637,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"b8c92e01-35c9-49be-87c6-ac876cb17477"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(128, 128, 128, 3)\n","(128, 3)\n","(21, 128, 128, 3)\n","(21, 3)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0RlArVRj74vM","executionInfo":{"status":"ok","timestamp":1683179115320,"user_tz":-120,"elapsed":284,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(layers.Rescaling(1/255)) # przez to, z wczytujemy batchami trzeba ustandaryzować używajać warstwy Rescaling\n","model.add(layers.Conv2D(32,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu',\n","                        input_shape=(img_width, img_heights, 3)))\n","\n","model.add(layers.MaxPool2D(2,2))\n","\n","model.add(layers.Conv2D(16,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu'\n","                        ))\n","\n","model.add(layers.MaxPool2D(2,2))\n","\n","model.add(layers.Flatten())\n","\n","model.add(layers.Dense(128,\n","                       activation='relu'))\n","\n","model.add(layers.Dense(3,\n","                       activation='softmax'))"],"metadata":{"id":"mAd75v8-7EYs","executionInfo":{"status":"ok","timestamp":1683181867440,"user_tz":-120,"elapsed":309,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', \n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"o59lvRdi81RY","executionInfo":{"status":"ok","timestamp":1683181878412,"user_tz":-120,"elapsed":608,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_ds,\n","                    validation_data=val_ds,\n","                    epochs=10,\n","                    batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeaS0kuJ9ILt","executionInfo":{"status":"ok","timestamp":1683182259755,"user_tz":-120,"elapsed":380314,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"2d8fccbb-8eb2-40a4-f61a-4d671cd19f6a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","8/8 [==============================] - 28s 3s/step - loss: 2.3039 - accuracy: 0.4482 - val_loss: 1.0842 - val_accuracy: 0.4716\n","Epoch 2/10\n","8/8 [==============================] - 25s 3s/step - loss: 1.0683 - accuracy: 0.5398 - val_loss: 1.0929 - val_accuracy: 0.4716\n","Epoch 3/10\n","8/8 [==============================] - 26s 3s/step - loss: 1.0884 - accuracy: 0.5398 - val_loss: 1.0906 - val_accuracy: 0.4716\n","Epoch 4/10\n","8/8 [==============================] - 25s 3s/step - loss: 1.0824 - accuracy: 0.5398 - val_loss: 1.0849 - val_accuracy: 0.4716\n","Epoch 5/10\n","8/8 [==============================] - 24s 3s/step - loss: 1.0716 - accuracy: 0.5398 - val_loss: 1.0771 - val_accuracy: 0.4716\n","Epoch 6/10\n","8/8 [==============================] - 25s 3s/step - loss: 1.0516 - accuracy: 0.5398 - val_loss: 1.0518 - val_accuracy: 0.4716\n","Epoch 7/10\n","8/8 [==============================] - 24s 3s/step - loss: 0.9845 - accuracy: 0.5300 - val_loss: 1.0352 - val_accuracy: 0.4760\n","Epoch 8/10\n","8/8 [==============================] - 24s 3s/step - loss: 0.9302 - accuracy: 0.5660 - val_loss: 1.1045 - val_accuracy: 0.4279\n","Epoch 9/10\n","8/8 [==============================] - 24s 3s/step - loss: 0.9189 - accuracy: 0.5518 - val_loss: 0.9692 - val_accuracy: 0.5284\n","Epoch 10/10\n","8/8 [==============================] - 24s 3s/step - loss: 0.8093 - accuracy: 0.6478 - val_loss: 0.8872 - val_accuracy: 0.5764\n"]}]},{"cell_type":"markdown","source":["## Second model\n","\n","A model to evaluate the impact of image quality on model efficiency. Images resolution and dimensions are higher."],"metadata":{"id":"VKOfyUiHV6Wh"}},{"cell_type":"markdown","source":["### First set\n","\n","The same conditions as for the previous model. An improvement in the model's efficiency can be seen, which means that the quality of the photo, and in particular the tread outlines clearly, affect the detection of the right type of tires."],"metadata":{"id":"PH5vmRnMi3Er"}},{"cell_type":"code","source":["# test_size = 0.2\n","# path = 'data'\n","\n","# for sub_type in ['1', '2', '3']:\n","#   os.makedirs(path + '/test_various_sizes' +f'/{sub_type}', exist_ok=True)\n","#   file_list = os.listdir(path + '/train_various_sizes/' + sub_type)\n","#   number_of_samples = int(len(file_list) * test_size)\n","\n","#   for file_name in random.sample(file_list, number_of_samples):\n","#     os.rename(path +'/train_various_sizes/' + sub_type + '/' + file_name,\n","#               path +'/test_various_sizes/' + sub_type + '/' + file_name)\n","\n","# train_path = 'data/train_various_sizes'\n","# test_path = 'data/test_various_sizes'\n","# print(len(os.listdir(train_path + '/1')))\n","# print(len(os.listdir(test_path + '/1')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mICGyxBeV7uG","executionInfo":{"status":"ok","timestamp":1683180085404,"user_tz":-120,"elapsed":853,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"51291c9c-8823-4f42-ec3e-b77326afbeb2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["603\n","150\n"]}]},{"cell_type":"code","source":["data_path = 'data/train_various_sizes'\n","\n","batch_size = 128\n","img_heights = 128\n","img_width = 128\n","\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683183390388,"user_tz":-120,"elapsed":4,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"vTYtZBrHZs4b"},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["train_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='training',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                    interpolation='bilinear',\n","                                                    seed=42)\n","\n","val_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='validation',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                  interpolation='bilinear',\n","                                                  seed=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683183392900,"user_tz":-120,"elapsed":801,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"5a6e3edb-4189-4353-cc0f-27a5cddfe327","id":"lKatoT3oZs4c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1145 files belonging to 3 classes.\n","Using 916 files for training.\n","Found 1145 files belonging to 3 classes.\n","Using 229 files for validation.\n"]}]},{"cell_type":"code","source":["model_1 = Sequential()\n","\n","model_1.add(layers.Rescaling(1/255)) # przez to, z wczytujemy batchami trzeba ustandaryzować używajać warstwy Rescaling\n","model_1.add(layers.Conv2D(32,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu',\n","                        input_shape=(img_width, img_heights, 3)))\n","\n","model_1.add(layers.MaxPool2D(2,2))\n","\n","model_1.add(layers.Conv2D(16,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu'\n","                        ))\n","\n","model_1.add(layers.MaxPool2D(2,2))\n","\n","model_1.add(layers.Flatten())\n","\n","model_1.add(layers.Dense(128,\n","                       activation='relu'))\n","\n","model_1.add(layers.Dense(3,\n","                       activation='softmax'))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683183395954,"user_tz":-120,"elapsed":579,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"IUPdHqLbZ1nY"},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["model_1.compile(optimizer='adam', \n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683183398246,"user_tz":-120,"elapsed":263,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"YKVTofTQZ1nY"},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["history_1 = model.fit(train_ds,\n","                    validation_data=val_ds,\n","                    epochs=10,\n","                    batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683183757852,"user_tz":-120,"elapsed":357371,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"0c66eed2-8ce9-46e3-a78e-87a0591597c6","id":"SpCottdYZ1nZ"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","8/8 [==============================] - 30s 3s/step - loss: 0.7607 - accuracy: 0.6758 - val_loss: 0.7600 - val_accuracy: 0.6812\n","Epoch 2/10\n","8/8 [==============================] - 31s 3s/step - loss: 0.6647 - accuracy: 0.7456 - val_loss: 0.7438 - val_accuracy: 0.6769\n","Epoch 3/10\n","8/8 [==============================] - 27s 3s/step - loss: 0.6067 - accuracy: 0.7511 - val_loss: 0.7778 - val_accuracy: 0.6900\n","Epoch 4/10\n","8/8 [==============================] - 27s 3s/step - loss: 0.6786 - accuracy: 0.6921 - val_loss: 0.8494 - val_accuracy: 0.6245\n","Epoch 5/10\n","8/8 [==============================] - 29s 3s/step - loss: 0.5381 - accuracy: 0.7828 - val_loss: 0.7578 - val_accuracy: 0.7205\n","Epoch 6/10\n","8/8 [==============================] - 27s 3s/step - loss: 0.4313 - accuracy: 0.8384 - val_loss: 0.8071 - val_accuracy: 0.6638\n","Epoch 7/10\n","8/8 [==============================] - 26s 3s/step - loss: 0.3790 - accuracy: 0.8603 - val_loss: 0.7557 - val_accuracy: 0.6856\n","Epoch 8/10\n","8/8 [==============================] - 26s 3s/step - loss: 0.3214 - accuracy: 0.8996 - val_loss: 0.7671 - val_accuracy: 0.6812\n","Epoch 9/10\n","8/8 [==============================] - 27s 3s/step - loss: 0.2652 - accuracy: 0.9247 - val_loss: 0.9977 - val_accuracy: 0.6638\n","Epoch 10/10\n","8/8 [==============================] - 27s 3s/step - loss: 0.2579 - accuracy: 0.9170 - val_loss: 0.9526 - val_accuracy: 0.6550\n"]}]},{"cell_type":"markdown","source":["### Second set\n","\n","The number of epochs was selected as the first hyperparameter. However, the result on the test set indicates an accuracy of the magnitude of 100%, while on the validation set it is about 65%. This means that the model tends to overfitting very strongly. So the number of observations should be increased."],"metadata":{"id":"RV2U5rlwjI6w"}},{"cell_type":"code","source":["data_path = 'data/train_various_sizes'\n","\n","batch_size = 128\n","img_heights = 128\n","img_width = 128\n","\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683184198179,"user_tz":-120,"elapsed":514,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"TNFHmGigjNIo"},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["train_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='training',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                    interpolation='bilinear',\n","                                                    seed=42)\n","\n","val_ds = keras.utils.image_dataset_from_directory(data_path,\n","                                                    validation_split=0.2,\n","                                                    subset='validation',\n","                                                    image_size = (img_heights, img_width),\n","                                                    batch_size = batch_size,\n","                                                    label_mode='categorical',\n","                                                  interpolation='bilinear',\n","                                                  seed=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683184199726,"user_tz":-120,"elapsed":1550,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"outputId":"ef4fe2d4-04f3-4940-fb2d-9cc7b8c9cb0d","id":"5z-tNTmejNIo"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1145 files belonging to 3 classes.\n","Using 916 files for training.\n","Found 1145 files belonging to 3 classes.\n","Using 229 files for validation.\n"]}]},{"cell_type":"code","source":["model_2 = Sequential()\n","\n","model_2.add(layers.Rescaling(1/255)) # przez to, z wczytujemy batchami trzeba ustandaryzować używajać warstwy Rescaling\n","model_2.add(layers.Conv2D(32,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu',\n","                        input_shape=(img_width, img_heights, 3)))\n","\n","model_2.add(layers.MaxPool2D(2,2))\n","\n","model_2.add(layers.Conv2D(16,\n","                        (3, 3),\n","                        padding='same',\n","                        activation='relu'\n","                        ))\n","\n","model_2.add(layers.MaxPool2D(2,2))\n","\n","model_2.add(layers.Flatten())\n","\n","model_2.add(layers.Dense(128,\n","                       activation='relu'))\n","\n","model_2.add(layers.Dense(3,\n","                       activation='softmax'))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683184203593,"user_tz":-120,"elapsed":449,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"Ax1wk4qDjNIp"},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["model_2.compile(optimizer='adam', \n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1683184209891,"user_tz":-120,"elapsed":273,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}},"id":"g7MfIQNgjNIp"},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["history_2 = model.fit(train_ds,\n","                    validation_data=val_ds,\n","                    epochs=20,\n","                    batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1febb19-1d1f-4121-8e54-2fd426802f57","id":"oRB9Nsx3jNIp","executionInfo":{"status":"ok","timestamp":1683184873334,"user_tz":-120,"elapsed":661914,"user":{"displayName":"Łukasz Zedler","userId":"15363775875426725218"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.2443 - accuracy: 0.9148 - val_loss: 0.7655 - val_accuracy: 0.6856\n","Epoch 2/20\n","8/8 [==============================] - 32s 4s/step - loss: 0.1823 - accuracy: 0.9443 - val_loss: 0.8223 - val_accuracy: 0.6812\n","Epoch 3/20\n","8/8 [==============================] - 26s 3s/step - loss: 0.1476 - accuracy: 0.9672 - val_loss: 0.8959 - val_accuracy: 0.6812\n","Epoch 4/20\n","8/8 [==============================] - 26s 3s/step - loss: 0.1145 - accuracy: 0.9738 - val_loss: 0.9259 - val_accuracy: 0.6725\n","Epoch 5/20\n","8/8 [==============================] - 29s 3s/step - loss: 0.0924 - accuracy: 0.9858 - val_loss: 0.9389 - val_accuracy: 0.6681\n","Epoch 6/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.0869 - accuracy: 0.9847 - val_loss: 0.9922 - val_accuracy: 0.6550\n","Epoch 7/20\n","8/8 [==============================] - 27s 3s/step - loss: 0.0661 - accuracy: 0.9913 - val_loss: 0.9978 - val_accuracy: 0.6419\n","Epoch 8/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.0632 - accuracy: 0.9956 - val_loss: 1.1227 - val_accuracy: 0.6419\n","Epoch 9/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.0483 - accuracy: 0.9956 - val_loss: 1.1927 - val_accuracy: 0.6463\n","Epoch 10/20\n","8/8 [==============================] - 29s 3s/step - loss: 0.0379 - accuracy: 0.9978 - val_loss: 1.1810 - val_accuracy: 0.6594\n","Epoch 11/20\n","8/8 [==============================] - 29s 3s/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 1.1556 - val_accuracy: 0.6419\n","Epoch 12/20\n","8/8 [==============================] - 25s 3s/step - loss: 0.0227 - accuracy: 0.9978 - val_loss: 1.2914 - val_accuracy: 0.6550\n","Epoch 13/20\n","8/8 [==============================] - 27s 3s/step - loss: 0.0185 - accuracy: 0.9989 - val_loss: 1.2518 - val_accuracy: 0.6638\n","Epoch 14/20\n","8/8 [==============================] - 27s 3s/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.6550\n","Epoch 15/20\n","8/8 [==============================] - 27s 3s/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.6507\n","Epoch 16/20\n","8/8 [==============================] - 29s 3s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3851 - val_accuracy: 0.6463\n","Epoch 17/20\n","8/8 [==============================] - 31s 4s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.6594\n","Epoch 18/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4431 - val_accuracy: 0.6507\n","Epoch 19/20\n","8/8 [==============================] - 25s 3s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.6638\n","Epoch 20/20\n","8/8 [==============================] - 28s 3s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.6550\n"]}]}]}